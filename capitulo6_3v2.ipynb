{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Carga de datos, Almacenamiento y Formatos de Archivos\n",
    "=========================================================\n",
    "\n",
    "#### IPN\n",
    "\n",
    "#### 20/nov/2020\n",
    "\n",
    "-   [Lectura y escritura de datos en formato de\n",
    "    texto](#lectura-y-escritura-de-datos-en-formato-de-texto)\n",
    "    -   [Lectura de Archivos de Texto, en\n",
    "        Segmentos](#lectura-de-archivos-de-texto-en-segmentos)\n",
    "    -   [Escritura de Datos en Formato de\n",
    "        Texto](#escritura-de-datos-en-formato-de-texto)\n",
    "    -   [Escritura de Datos en Formato de\n",
    "        Texto](#escritura-de-datos-en-formato-de-texto-1)\n",
    "    -   [Datos JSON](#datos-json)\n",
    "    -   [XML y HTML](#xml-y-html)\n",
    "-   [Formatos de datos binarios](#formatos-de-datos-binarios)\n",
    "    -   [Formato HDF5](#formato-hdf5)\n",
    "    -   [Archivos de Microsoft Excel](#archivos-de-microsoft-excel)\n",
    "-   [Interacción con APIs para web](#interacción-con-apis-para-web)\n",
    "-   [Interacción con bases de datos](#interacción-con-bases-de-datos)\n",
    "-   [Bibliografía](#bibliografía)\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "NOTA: *Los archivos examples y datasets se pueden obtener del sitio\n",
    "<a href=\"https://github.com/wesm/pydata-book\" class=\"uri\">https://github.com/wesm/pydata-book</a>*\n",
    "\n",
    " \n",
    "\n",
    "Acceder a los datos es un primer paso necesario para usar la mayoría de\n",
    "las herramientas de este curso. Nos enfocaremos en la entrada y salida\n",
    "de datos usando pandas, aunque hay numerosas herramientas en otras\n",
    "bibliotecas para ayudar con la lectura y escritura de datos en varios\n",
    "formatos. La entrada y salida generalmente se dividen en algunas\n",
    "categorías principales:\n",
    "\n",
    "-   Leer archivos de texto y otros formatos en disco más eficientes\n",
    "-   Cargar datos de bases de datos\n",
    "-   Interactuar con fuentes de red como APIs de web.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "Lectura y escritura de datos en formato de texto\n",
    "------------------------------------------------\n",
    "\n",
    " \n",
    "\n",
    "pandas presenta una serie de funciones para leer datos tabulares como un\n",
    "objeto DataFrame. La siguiente tabla resume algunos de ellos, aunque es\n",
    "probable que `read_csv` y `read_table` sean los más utilizados.\n",
    "\n",
    " \n",
    "\n",
    "#### Funciones de pandas para Entrada/Salida\n",
    "\n",
    "| *Función*               | *Descripción*                                                                   |\n",
    "|:------------------------|:--------------------------------------------------------------------------------|\n",
    "| `pandas.read_clipboard` | Lee el texto del portapapeles y lo pasa a `read_csv`.                           |\n",
    "| `pandas.read_csv`       | Lea un archivo de valores separados por comas (csv) en el DataFrame.            |\n",
    "| `pandas.read_excel`     | Lea un archivo Excel en un DataFrame de pandas.                                 |\n",
    "| `pandas.read_feather`   | Carga un objeto con formato feather desde la ruta del archivo.                  |\n",
    "| `pandas.read_fwf`       | Lea una tabla de líneas formateadas de ancho fijo en el DataFrame.              |\n",
    "| `pandas.read_hdf`       | Lee del almacenamiento, ciérralo si lo abrimos.                                 |\n",
    "| `pandas.read_html`      | Lee tablas HTML en una lista de objetos DataFrame.                              |\n",
    "| `pandas.read_json`      | Convierte una cadena JSON en objeto pandas.                                     |\n",
    "| `pandas.read_pickle`    | Carga el objeto pandas en formato pickle (o cualquier objeto) desde un archivo. |\n",
    "| `pandas.read_sas`       | Lee los archivos SAS almacenados como archivos de formato XPORT o SAS7BDAT.     |\n",
    "| `pandas.read_sql`       | Lee la tabla de consulta o base de datos SQL en un DataFrame.                   |\n",
    "| `pandas.read_stata`     | Lee el archivo Stata en un DataFrame.                                           |\n",
    "| `pandas.read_table`     | Lea el archivo delimitado general en un DataFrame.                              |\n",
    "\n",
    " \n",
    "\n",
    "Estas funciones convierten datos de texto en un DataFrame. Los\n",
    "argumentos opcionales para estas funciones pueden clasificarse en las\n",
    "siguientes categorías:\n",
    "\n",
    "-   ***Indexación***. Como DataFrame retornado puede obtener una o más\n",
    "    columnas, y si desea puede obtener nombres de columna del archivo,\n",
    "    obtener el usuario, o nada.\n",
    "\n",
    "-   ***Inferencia de tipos y conversión de datos*** Esto incluye las\n",
    "    conversiones de valores definidos por el usuario y la lista\n",
    "    personalizada de marcadores de valores faltantes.\n",
    "\n",
    "-   ***Análisis de fecha y hora*** Incluye la capacidad de combinación,\n",
    "    incluida la combinación de información de fecha y hora distribuida\n",
    "    en varias columnas en una sola columna en el resultado.\n",
    "\n",
    "-   ***Iteración*** Soporte para iterar sobre fragmentos de archivos muy\n",
    "    grandes.\n",
    "\n",
    "-   ***Problemas de datos no-limpios*** Saltar filas o un pie de página,\n",
    "    comentarios u otras cosas menores como datos numéricos con miles\n",
    "    separados por comas.\n",
    "\n",
    " \n",
    "\n",
    "Debido a lo desordenado que pueden ser los datos en el mundo real,\n",
    "algunas de las funciones de carga de datos (especialmente `read_csv`) se\n",
    "han vuelto muy complejas en sus opciones. Es normal sentirse abrumado\n",
    "por la cantidad de parámetros diferentes (`read_csv` tiene más de 50 al\n",
    "momento de escribir esto). La documentación de pandas en línea tiene\n",
    "muchos ejemplos sobre cómo funciona cada uno de ellos, por lo que si\n",
    "tiene dificultades para leer un archivo en particular, puede haber un\n",
    "ejemplo lo suficientemente similar como para ayudarlo a encontrar los\n",
    "parámetros correctos.\n",
    "\n",
    "Algunas de estas funciones, como `pandas.read_csv`, realizan *inferencia\n",
    "de tipos*, porque los tipos de datos de columna no forman parte del\n",
    "formato de datos. Esto significa que no necesariamente tenemos que\n",
    "especificar qué columnas son numéricas, enteras, booleanas o de cadena.\n",
    "Otros formatos de datos, como HDF5, Feather y msgpack, tienen los tipos\n",
    "de datos almacenados en el formato.\n",
    "\n",
    "El manejo de fechas y otros tipos personalizados pueden requerir un\n",
    "esfuerzo adicional. Comencemos con un pequeño archivo de texto separado\n",
    "por comas (CSV):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  !cat \"./examples/ex1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aquí utilizamos el comando de Linux `cat` para imprimir el contenido sin\n",
    "formato del archivo en la pantalla. En Windows usamos:\n",
    "\n",
    " \n",
    "\n",
    "``` p\n",
    "In [3]: !type \"C: … \\examples\\ex1.csv\"\n",
    "a,b,c,d,message\n",
    "1,2,3,4,hello\n",
    "5,6,7,8,world\n",
    "9,10,11,12,foo\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "Como el archivo está delimitado por comas, podemos usar `read_csv` para\n",
    "leerlo en un DataFrame:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "In [4]: df = pd.read_csv(\"/media/linux/Gateway/Documents and Settings/DavidJ/Documents/Python/CURSO_DE_PYTHON/LIBROS/O'Reilly/pydata-book-2nd-edition/examples/ex1.csv\")\n",
    "\n",
    "In [5]: df\n",
    "Out[5]: \n",
    "   a   b   c   d message\n",
    "0  1   2   3   4   hello\n",
    "1  5   6   7   8   world\n",
    "2  9  10  11  12     foo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "También podríamos haber usado `read_table` y especificado el\n",
    "delimitador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "df = pd.read_table(\"./examples/ex1.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí utilizamos el comando de Linux `cat` para imprimir el contenido sin\n",
    "formato del archivo en la pantalla. En Windows usamos:\n",
    "\n",
    " \n",
    "\n",
    "``` p\n",
    "In [3]: !type \"C: … \\examples\\ex1.csv\"\n",
    "a,b,c,d,message\n",
    "1,2,3,4,hello\n",
    "5,6,7,8,world\n",
    "9,10,11,12,foo\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "Como el archivo está delimitado por comas, podemos usar `read_csv` para\n",
    "leerlo en un DataFrame:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./examples/ex1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podríamos haber usado `read_table` y especificado el\n",
    "delimitador:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(\"./examples/ex1.csv\", sep=',')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Un archivo no siempre tendrá una fila de encabezado. Consideremos este\n",
    "archivo:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "!cat \"./examples/ex2.csv\"\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para leer este archivo, tenemos un par de opciones. Podemos permitir que\n",
    "pandas asigne nombres de columna predeterminados, o podemos especificar\n",
    "los nombres:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./examples/ex2.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pd.read_csv(\"./examples/ex2.csv\", names=['a', 'b', 'c', 'd', 'message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que se desea que la columna `message` sea el índice del\n",
    "DataFrame retornado. Podemos indicar que desea la columna en el índice 4\n",
    "o nombrada `message` usando el argumento `index_col`:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que se desea que la columna `message` sea el índice del\n",
    "DataFrame retornado. Podemos indicar que desea la columna en el índice 4\n",
    "o nombrada `message` usando el argumento `index_col`:\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['a', 'b', 'c', 'd', 'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./examples/ex2.csv\", names=names, index_col='message')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de que deseemos formar un índice jerárquico a partir de\n",
    "varias columnas, pasamos una lista de números o nombres de columna:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !cat \"./examples/csv_mindex.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de que deseemos formar un índice jerárquico a partir de\n",
    "varias columnas, pasamos una lista de números o nombres de columna:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = pd.read_csv(\"./examples/csv_mindex.csv\", index_col=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos, puede que una tabla no tenga un delimitador fijo,\n",
    "usando espacios en blanco o algún otro patrón para separar los campos.\n",
    "Consideremos un archivo de texto que se ve así:\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  list(open(\"./examples/ex3.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los campos aquí están separados por una cantidad variable de espacios en\n",
    "blanco. En estos casos, podemos pasar una expresión regular como\n",
    "delimitador para `read_table`. Esto se puede expresar con la expresión\n",
    "regular `\\s+`, entonces tenemos:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.read_table(\"./examples/ex3.txt\", sep='\\s+') #pd.read_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como había un nombre de columna menos que el número de filas de datos,\n",
    "`read_table` infiere que la primera columna debería ser el índice del\n",
    "DataFrame en este caso especial.\n",
    "\n",
    "Las funciones del analizador tienen muchos argumentos adicionales para\n",
    "manejar la amplia variedad de formatos de archivo. Por ejemplo, podemos\n",
    "omitir la primera, tercera y cuarta fila de un archivo con `skiprows`:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"./examples/ex4.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  pd.read_csv(\"./examples/ex4.csv\", skiprows=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El manejo de valores perdidos es una parte importante y sutil del\n",
    "proceso de análisis de archivos. Los datos faltantes generalmente no\n",
    "están presentes (cadena vacía) o están marcados por algún valor\n",
    "*centinela*. Por “default”, los pandas usan un conjunto de centinelas\n",
    "comunes, como `NA` y `NULL`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"./examples/ex5.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.read_csv(\"./examples/ex5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La opción `na_values` puede tomar una lista o un conjunto de cadenas\n",
    "para considerar los valores faltantes:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.read_csv(\"./examples/ex5.csv\", na_values=['NULL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden especificar diferentes centinelas de `NA` para cada columna:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centinelas = {'message': ['foo', 'NA'], 'something': ['two']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./examples/ex5.csv\", na_values = centinelas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "La siguiente tabla enumera algunas opciones de uso frecuente en\n",
    "`pandas.read_csv` y `pandas.read_table`.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "#### Algunos argumentos de la función `read_csv/read_table`\n",
    "\n",
    "<table style=\"width:99%;\">\n",
    "<colgroup>\n",
    "<col style=\"width: 23%\" />\n",
    "<col style=\"width: 76%\" />\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"header\">\n",
    "<th style=\"text-align: left;\"><em>Argumento</em></th>\n",
    "<th style=\"text-align: left;\"><em>Descripción</em></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">chunksize</td>\n",
    "<td style=\"text-align: left;\">Retorna el objeto TextFileReader para la iteración.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">comment</td>\n",
    "<td style=\"text-align: left;\">Indica que el resto de la línea no debe analizarse.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">converters</td>\n",
    "<td style=\"text-align: left;\">Dict de funciones para convertir valores en ciertas columnas. Las claves pueden ser enteros o etiquetas de columna.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">date_parser</td>\n",
    "<td style=\"text-align: left;\">Función que se utiliza para convertir una secuencia de columnas de cadena en un arreglo de instancias de fecha y hora.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">dayfirst</td>\n",
    "<td style=\"text-align: left;\">Fechas en formato DD/MM, formato internacional y Europeo.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">encoding</td>\n",
    "<td style=\"text-align: left;\">Codificación a usar para UTF al leer/escribir (ej. “Utf-8”). Lista de codificaciones estándar de Python.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">filepath_or_buffer</td>\n",
    "<td style=\"text-align: left;\">Cualquier ruta de cadena válida es aceptable. La cadena podría ser una URL</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">header</td>\n",
    "<td style=\"text-align: left;\">Número(s) de fila para usar como nombres de columna y el inicio de los datos.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">index_col</td>\n",
    "<td style=\"text-align: left;\">Columnas(s) a usar como etiquetas de fila del DataFrame, ya sea como nombre de cadena o índice de columna. Si se da una secuencia de int/str, se usa un MultiIndex.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">iterator</td>\n",
    "<td style=\"text-align: left;\">Retorna el objeto TextFileReader para iterar u obtener fragmentos con get_chunk().</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">keep_date_col</td>\n",
    "<td style=\"text-align: left;\">Si True y parse_dates especifica la combinación de varias columnas, mantenga las columnas originales.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">names</td>\n",
    "<td style=\"text-align: left;\">Lista de nombres de columna para usar. Si el archivo contiene una fila de encabezado, debe pasar explícitamente header = 0 para anular los nombres de columna. No se permiten duplicados en esta lista.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">na_values</td>\n",
    "<td style=\"text-align: left;\">Cadenas adicionales para reconocer como NA / NaN.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">nrows</td>\n",
    "<td style=\"text-align: left;\">Número de filas de archivo para leer. Útil para leer piezas de archivos grandes.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">parse_dates</td>\n",
    "<td style=\"text-align: left;\">El comportamiento es el siguiente:<br />\n",
    "<strong><em>- booleano</em></strong>. Si es verdadero -&gt; intenta analizar el índice.<br />\n",
    "<strong><em>- lista de int o nombres</em></strong>. p.ej. Si [1, 2, 3] -&gt; intenta analizar las columnas 1, 2, 3 cada una como una columna de fecha separada.<br />\n",
    "lista de listas p.ej. Si [[1, 3]] -&gt; combina las columnas 1 y 3 y analiza como una sola columna de fecha.<br />\n",
    "<strong><em>- dict</em></strong>, p. e. {‘Foo’: [1, 3]} -&gt; analiza las columnas 1, 3 como fecha y resultado de la llamada ‘foo’</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">Sep o delimiter</td>\n",
    "<td style=\"text-align: left;\">Delimitador a utilizar.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">skiprows</td>\n",
    "<td style=\"text-align: left;\">Números de línea para omitir (índice 0) o número de líneas para omitir (int) al comienzo del archivo.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">skipfooter</td>\n",
    "<td style=\"text-align: left;\">Número de líneas en la parte inferior del archivo que se omitirá (no se admite con motor = “c”).</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">squeeze</td>\n",
    "<td style=\"text-align: left;\">Si los datos analizados solo contienen una columna, retorna una Serie.</td>\n",
    "</tr>\n",
    "<tr class=\"even\">\n",
    "<td style=\"text-align: left;\">thousands</td>\n",
    "<td style=\"text-align: left;\">Separador de millares.</td>\n",
    "</tr>\n",
    "<tr class=\"odd\">\n",
    "<td style=\"text-align: left;\">verbose</td>\n",
    "<td style=\"text-align: left;\">Indique el número de valores de NA colocados en columnas no numéricas.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### Lectura de Archivos de Texto, en Segmentos\n",
    "\n",
    " \n",
    "\n",
    "Cuando procesamos archivos muy grandes o queremos encontrar el conjunto\n",
    "adecuado de argumentos para procesar correctamente un archivo grande, es\n",
    "posible que solo deseemos leer una pequeña parte del archivo o iterar a\n",
    "través de fragmentos más pequeños del archivo.\n",
    "\n",
    "Antes de mirar un archivo grande, hacemos que la configuración de\n",
    "visualización de pandas sea más compacta:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Ahora tenemos:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.read_csv( \"./examples/ex6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para leer una pequeña cantidad de filas usamos `nrows`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./examples/ex6.csv\", nrows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para leer un archivo en segmentos especifique `chunksize` como un número\n",
    "de filas:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = pd.read_csv(\"./examples/ex6.csv\", chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objeto TextParser retornado por `read_csv` permite iterar sobre las\n",
    "partes del archivo de acuerdo con el tamaño de `chunksize`. Por ejemplo,\n",
    "podemos iterar sobre `ex6.csv`, agregando los recuentos de valores en la\n",
    "columna `key`’ de la siguiente manera:\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = pd.read_csv(\"./examples/ex6.csv\", chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = pd.Series([],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for piece in chunker:\n",
    "    ...:     tot = tot.add(piece['key'].value_counts(), fill_value=0)\n",
    "    ...:     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = tot.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Tenemos entonces:\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "TextParser también está equipado con un método `get_chunk` que permite\n",
    "leer segmentos de un tamaño arbitrario.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### Escritura de Datos en Formato de Texto\n",
    "\n",
    " \n",
    "\n",
    "Los datos también se pueden exportar a un formato con diferente\n",
    "delimitador. Consideremos uno de los archivos CSV leídos anteriormente:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./examples/ex5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Con el método `to_csv` de DataFrame, podemos escribir los datos en un\n",
    "archivo separado por comas:\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./examples/out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [19]: !cat \"./examples/out.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Por supuesto podemos usar otros delimitadores escribiendo en\n",
    "`sys.stdout` para que imprima el texto en la consola:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sys.stdout, sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Los valores faltantes aparecen como cadenas vacías en la salida. Es\n",
    "posible que desee denotarlos por algún otro valor centinela:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sys.stdout, na_rep='NULL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Si no se especifican otras opciones, se escriben las etiquetas de fila y\n",
    "columna. Ambas pueden deshabilitarse:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sys.stdout, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos escribir solo un subconjunto de las columnas, y en el\n",
    "orden deseado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(sys.stdout, index=False, columns=['a', 'b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series también tiene un método `to_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('1/1/2000', periods=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.arange(7), index=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.to_csv(\"./examples/tseries.csv\", header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"./examples/tseries.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    "### Escritura de Datos en Formato de Texto\n",
    "\n",
    " \n",
    "\n",
    "Es posible cargar la mayoría de las formas de datos tabulares del disco\n",
    "utilizando funciones como `pandas.read_table`. Sin embargo en algunos\n",
    "casos es necesario algún procesamiento manual. No es raro recibir un\n",
    "archivo con una o más líneas mal formadas que confundan a `read_table`.\n",
    "Para ilustrar las herramientas básicas, consideremos un pequeño archivo\n",
    "CSV:\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"./examples/ex7.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Para cualquier archivo con un delimitador de un solo carácter, podemos\n",
    "usar el módulo interno de Python `csv`. Para usarlo, pasamos cualquier\n",
    "archivo abierto u objeto similar a un archivo a `csv.reader`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./examples/ex7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lector = csv.reader(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Iterar a través de lector como un archivo produce tuplas de valores con\n",
    "cualquier carácter de comillas eliminado:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lector:\n",
    "   ...:     print(line)\n",
    "   ...:     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de ahí, podemos hacer los arreglos necesarios para poner los\n",
    "datos en la forma deseada. Veamos esto paso a paso. Primero, leemos el\n",
    "archivo en una lista de líneas:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./examples/ex7.csv\") as f:      \n",
    "   ...:     líneas = list(csv.reader(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    "Luego, dividimos las líneas en la línea de encabezado y las líneas de\n",
    "datos:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, values = líneas[0], líneas[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    "Luego podemos crear un diccionario de columnas de datos utilizando una\n",
    "comprensión del diccionario y la expresión `zip (* values)`, que\n",
    "transpone filas a columnas:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {h: v for h, v in zip(header, zip(*values))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Los archivos CSV vienen en muchos sabores diferentes. Para definir un\n",
    "nuevo formato con un delimitador diferente, una convención de comillas o\n",
    "un terminador de línea diferente, definimos una subclase simple de\n",
    "`csv.Dialect`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dialect(csv.Dialect):    #solo texto\n",
    " ...:   lineterminator = '\\n'\n",
    " ...:   delimiter = ';'\n",
    " ...:   quotechar = '\"'\n",
    " ...:   quoting = csv.QUOTE_MINIMAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reader = csv.reader(f, dialect=my_dialect)                 # texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    "También podemos proporcionar parámetros de dialecto CSV individuales a\n",
    "csv.reader sin tener que definir una subclase:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reader = csv.reader(f, delimiter='|')  # solo texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "### Datos JSON\n",
    "\n",
    " \n",
    "\n",
    "JSON (abreviatura de JavaScript Object Notation) se ha convertido en uno\n",
    "de los formatos estándar para enviar datos por solicitud HTTP entre\n",
    "navegadores web y otras aplicaciones. Es un formato de datos mucho más\n",
    "libre que una forma tabular de texto como CSV. Por ejemplo:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "#### Opciones para dialectos CSV\n",
    "\n",
    "| *Argumento*        | *Descripción*                                                                                                                                                                                                                                                                                                            |\n",
    "|:-------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `delimiter`        | Cadena de un carácter utilizada para separar campos. El valor de “default” es `','`.                                                                                                                                                                                                                                     |\n",
    "| `doublequote`      | Controla cómo se deben citar las instancias de *quotechar* que aparecen dentro de un campo. Cuando es `True`, el carácter se duplica. Cuando es `False`, el *escapechar* se usa como prefijo del *quotechar*. Por “default” es `True`.                                                                                   |\n",
    "| `escapechar`       | Cadena de un carácter utilizada por el escritor para escapar del *delimiter* si la cita se establece en `QUOTE_NONE` y del *quotechar* si *doublequote* es `False`. Al leer, el *escapechar* elimina cualquier significado especial del siguiente carácter. Su valor de “default” es `None`, lo que desactiva el escape. |\n",
    "| `lineterminator`   | La cadena utilizada para terminar las líneas producidas por el escritor. El valor de “default” es `'\\r\\n'`.                                                                                                                                                                                                              |\n",
    "| `quotechar`        | Cadena de un carácter utilizada para citar campos que contienen caracteres especiales, como el *delimiter* o *quotechar*, o que contienen caracteres de nueva-línea. El valor de “default” es `‘ ” ’`.                                                                                                                   |\n",
    "| `quoting`          | Controla cuándo las citas deben ser generadas por el escritor y reconocidas por el lector. Puede tomar cualquiera de las constantes `QUOTE_*` y el valor de “default” es `QUOTE_MINIMAL`.                                                                                                                                |\n",
    "| `skipinitialspace` | Cuando es `True`, se ignora el espacio en blanco que sigue inmediatamente al *delimiter*. El valor de “default” es `False`.                                                                                                                                                                                              |\n",
    "| `strict`           | Cuando es `True`, genera la excepción `Error` en una entrada CSV incorrecta. El valor de “default” es `False`.                                                                                                                                                                                                           |\n",
    "\n",
    " \n",
    "\n",
    "Para archivos con delimitadores mas complicados o de caracteres\n",
    "múltiples, no es posible utilizar el módulo csv. En esos casos, tenemos\n",
    "que usar seccionamiento de líneas y otra limpieza utilizando el método\n",
    "de cadena `split` o el método de expresión regular `re.split`.\n",
    "\n",
    "Para escribir manualmente archivos delimitados, podemos usar\n",
    "`csv.writer` el cual acepta un objeto de archivo abierto y grabable y\n",
    "las mismas opciones de dialecto y formato que `csv.reader`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "... p                                                      # solo texto\n",
    "writer.writerow(('one', 'two', 'three')) \n",
    " ...: writer.writerow(('1', '2', '3')) \n",
    " ...: writer.writerow(('4', '5', '6')) \n",
    " ...: writer.writerow(('7', '8', '9')) \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"\"\"\n",
    "    ...:        {\"name\": \"Wes\",\n",
    "    ...:         \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    "    ...:         \"pet\": null,\n",
    "    ...:         \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
    "    ...:                {\"name\": \"Katie\", \"age\": 38,  \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}] \n",
    "    ...:}\n",
    "    ...: \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "JSON es un código de Python casi válido con la excepción de su valor\n",
    "nulo `null` y algunos otros matices (como no permitir las comas finales\n",
    "al final de las listas). Los tipos básicos son objetos (dicts), arreglos\n",
    "(listas), cadenas, números, booleanos y nulos. Todas las claves en un\n",
    "objeto deben ser cadenas. Hay varias bibliotecas de Python para leer y\n",
    "escribir datos JSON. Usaremos `json`, ya que es interno en la biblioteca\n",
    "estándar de Python. Para convertir una cadena JSON a Python usamos\n",
    "`json.loads`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = json.loads(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Por otro lado `json.dumps` convierte un objeto Python de nuevo a JSON:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_json = json.dumps(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    "Depende del usuario cómo convertir un objeto JSON o una lista de objetos\n",
    "en un DataFrame u otra estructura de datos para su análisis.\n",
    "Convenientemente, es posible pasar una lista de dicts (que anteriormente\n",
    "eran objetos JSON) al constructor DataFrame y seleccionar un subconjunto\n",
    "de los campos de datos.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings = pd.DataFrame(result['siblings'], columns=['name', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "`pandas.read_json` puede convertir automáticamente conjuntos de datos\n",
    "JSON en arreglos específicos en una Serie o un DataFrame. Por ejemplo:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"./examples/example.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Las opciones de “default” para `pandas.read_json` suponen que cada\n",
    "objeto en el arreglo JSON es una fila en la tabla:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"./examples/example.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma de exportar datos de pandas a JSON, es usar los métodos\n",
    "`to_json` en Series y DataFrame:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "### XML y HTML\n",
    "\n",
    " \n",
    "\n",
    "Python tiene muchas bibliotecas para leer y escribir datos en los\n",
    "omnipresentes formatos HTML y XML. Los ejemplos incluyen lxml, Beautiful\n",
    "Soup y html5lib. Mientras que lxml es comparativamente mucho más rápido\n",
    "en general, las otras bibliotecas pueden manejar mejor los archivos HTML\n",
    "o XML que tengan formato incorrecto.\n",
    "\n",
    "pandas tiene una función interna, `read_html`, que usa bibliotecas como\n",
    "lxml y Beautiful Soup para analizar automáticamente las tablas de los\n",
    "archivos HTML como objetos DataFrame. Para mostrar cómo funciona esto,\n",
    "el autor descargó un archivo HTML (utilizado en la documentación de los\n",
    "pandas) de la agencia gubernamental de la FDIC de los Estados Unidos que\n",
    "muestra quiebras bancarias. Primero, es necesario instalar algunas\n",
    "bibliotecas adicionales utilizadas por `read_html`:\n",
    "\n",
    " \n",
    " \n",
    "conda install lxml\n",
    "pip install beautifulsoup4 html5lib\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "La función `pandas.read_html` tiene varias opciones, pero por “default”\n",
    "busca e intenta analizar todos los datos tabulares contenidos en\n",
    "\n",
    "tags\\`. El resultado es una lista de objetos DataFrame:\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablas = pd.read_html(\"./examples/fdic_failed_bank_list.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallas = tablas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[30]: \n",
    "                      Bank Name  ...       Updated Date\n",
    "0                   Allied Bank  ...  November 17, 2016\n",
    "1  The Woodbury Banking Company  ...  November 17, 2016\n",
    "2        First CornerStone Bank  ...  September 6, 2016\n",
    "3            Trust Company Bank  ...  September 6, 2016\n",
    "4    North Milwaukee State Bank  ...      June 16, 2016\n",
    "\n",
    "[5 rows x 7 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Para obtener todas las columnas hacer:\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[32]: \n",
    "                      Bank Name             City  ST   CERT  \\\n",
    "0                   Allied Bank         Mulberry  AR     91   \n",
    "1  The Woodbury Banking Company         Woodbury  GA  11297   \n",
    "2        First CornerStone Bank  King of Prussia  PA  35312   \n",
    "3            Trust Company Bank          Memphis  TN   9956   \n",
    "4    North Milwaukee State Bank        Milwaukee  WI  20364   \n",
    "\n",
    "                 Acquiring Institution        Closing Date       Updated Date  \n",
    "0                         Today's Bank  September 23, 2016  November 17, 2016  \n",
    "1                          United Bank     August 19, 2016  November 17, 2016  \n",
    "2  First-Citizens Bank & Trust Company         May 6, 2016  September 6, 2016  \n",
    "3           The Bank of Fayette County      April 29, 2016  September 6, 2016  \n",
    "4  First-Citizens Bank & Trust Company      March 11, 2016      June 16, 2016  \n",
    "```\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que `fallas` tienen muchas columnas, pandas inserta un carácter\n",
    "de salto de línea `\\`.\n",
    "\n",
    "Aquí podríamos proceder a realizar algunos análisis y limpieza de datos,\n",
    "como calcular el número de quiebras bancarias por año:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_timestamps = pd.to_datetime(fallas['Closing Date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_timestamps.dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[34]: \n",
    "2010    157\n",
    "2009    140\n",
    "2011     92\n",
    "2012     51\n",
    "2008     25\n",
    "2013     24\n",
    "2014     18\n",
    "2002     11\n",
    "2015      8\n",
    "2016      5\n",
    "2004      4\n",
    "2001      4\n",
    "2007      3\n",
    "2003      3\n",
    "2000      2\n",
    "Name: Closing Date, dtype: int64\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizando XML con lxml.objectify\n",
    "\n",
    " \n",
    "\n",
    "XML (eXtensible Markup Language) es otro formato común de datos\n",
    "estructurados, que admite datos jerárquicos y anidados con metadatos.\n",
    "\n",
    "La función `pandas.read_html`, mostrada anteriormente usa lxml o\n",
    "Beautiful Soup para analizar datos de HTML. XML y HTML son\n",
    "estructuralmente similares, pero XML es más general. Mostraremos un\n",
    "ejemplo de cómo usar lxml para analizar datos de un formato XML más\n",
    "general.\n",
    "\n",
    "La Autoridad de Transporte Metropolitano de Nueva York (MTA) publica una\n",
    "serie de datos sobre sus servicios de autobús y tren. Aquí veremos los\n",
    "datos de rendimiento, que están contenidos en un conjunto de archivos\n",
    "XML. Cada servicio de tren o autobús tiene un archivo diferente que\n",
    "contiene datos mensuales como una serie de registros XML que se ven así:\n",
    "\n",
    " \n",
    "\n",
    "``` p\n",
    "<INDICATOR>\n",
    "  <INDICATOR_SEQ>373889</INDICATOR_SEQ>\n",
    "  <PARENT_SEQ></PARENT_SEQ>\n",
    "  <AGENCY_NAME>Metro-North Railroad</AGENCY_NAME>\n",
    "  <INDICATOR_NAME>Escalator Availability</INDICATOR_NAME>\n",
    "  <DESCRIPTION>Percent of the time that escalators are operational\n",
    "  systemwide. The availability rate is based on physical observations performed\n",
    "  the morning of regular business days only. This is a new indicator the agency\n",
    "  began reporting in 2009.</DESCRIPTION>\n",
    "  <PERIOD_YEAR>2011</PERIOD_YEAR>\n",
    "  <PERIOD_MONTH>12</PERIOD_MONTH>\n",
    "  <CATEGORY>Service Indicators</CATEGORY>\n",
    "  <FREQUENCY>M</FREQUENCY>\n",
    "  <DESIRED_CHANGE>U</DESIRED_CHANGE>\n",
    "  <INDICATOR_UNIT>%</INDICATOR_UNIT>\n",
    "  <DECIMAL_PLACES>1</DECIMAL_PLACES>\n",
    "  <YTD_TARGET>97.00</YTD_TARGET>\n",
    "  <YTD_ACTUAL></YTD_ACTUAL>\n",
    "  <MONTHLY_TARGET>97.00</MONTHLY_TARGET>\n",
    "  <MONTHLY_ACTUAL></MONTHLY_ACTUAL>\n",
    "</INDICATOR>\n",
    "```\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando `lxml.objectify`, analizamos el archivo y obtenemos una\n",
    "referencia al nodo raíz del archivo XML con `getroot`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/mta_perf/Performance_MNR.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = objectify.parse(open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = parsed.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    "`root.INDICATOR` retorna un generador que produce cada elemento\n",
    "`<INDICATOR>XML`. Para cada registro, podemos completar un dict de\n",
    "nombres de etiquetas (como `YTD_ACTUAL`) a valores de datos (excluyendo\n",
    "algunas etiquetas):\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_fields = ['PARENT_SEQ', 'INDICATOR_SEQ', 'DESIRED_CHANGE', 'DECIMAL_PLACES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in root.INDICATOR:\n",
    "    ...:     el_data = {}\n",
    "    ...:     for child in elt.getchildren():\n",
    "    ...:         if child.tag in skip_fields:\n",
    "    ...:             continue\n",
    "    ...:         el_data[child.tag] = child.pyval\n",
    "    ...:     datos.append(el_data)\n",
    "    ...:     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Por último, convertimos esta lista de dicts en un DataFrame:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [67]: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[68]: \n",
    "            AGENCY_NAME                        INDICATOR_NAME  \\\n",
    "0  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
    "1  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
    "2  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
    "3  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
    "4  Metro-North Railroad  On-Time Performance (West of Hudson)   \n",
    "\n",
    "                                         DESCRIPTION  PERIOD_YEAR  \\\n",
    "0  Percent of commuter trains that arrive at thei...         2008   \n",
    "1  Percent of commuter trains that arrive at thei...         2008   \n",
    "2  Percent of commuter trains that arrive at thei...         2008   \n",
    "3  Percent of commuter trains that arrive at thei...         2008   \n",
    "4  Percent of commuter trains that arrive at thei...         2008   \n",
    "\n",
    "   PERIOD_MONTH            CATEGORY FREQUENCY INDICATOR_UNIT YTD_TARGET  \\\n",
    "0             1  Service Indicators         M              %         95   \n",
    "1             2  Service Indicators         M              %         95   \n",
    "2             3  Service Indicators         M              %         95   \n",
    "3             4  Service Indicators         M              %         95   \n",
    "4             5  Service Indicators         M              %         95   \n",
    "\n",
    "  YTD_ACTUAL MONTHLY_TARGET MONTHLY_ACTUAL  \n",
    "0       96.9             95           96.9  \n",
    "1         96             95             95  \n",
    "2       96.3             95           96.9  \n",
    "3       96.8             95           98.3  \n",
    "4       96.6             95           95.8  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Los datos XML pueden ser mucho más complicados que este ejemplo. Cada\n",
    "etiqueta también puede tener metadatos. Consideremos una etiqueta de\n",
    "enlace HTML, que también es XML válido:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = '<a href=\"http://www.google.com\">Google</a>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = objectify.parse(StringIO(tag)).getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    "Ahora podemos acceder a cualquiera de los campos (como `href` ) en la\n",
    "etiqueta o el texto del enlace:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Out[72]: <Element a at 0x7f2574505680>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "In [73]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[73]: 'http://www.google.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [74]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatos de datos binarios\n",
    "--------------------------\n",
    "\n",
    " \n",
    "\n",
    "Una de las formas más fáciles de almacenar datos   —también conocida\n",
    "como *serialización*—   de manera eficiente en formato binario es usar\n",
    "la serialización interna de Python, `pickle` . Todos los objetos pandas\n",
    "tienen un método `to_pickle` que escribe los datos en el disco en\n",
    "formato pickle:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv(\"./examples/ex1.csv\")\n",
    "\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[76]: \n",
    "   a   b   c   d message\n",
    "0  1   2   3   4   hello\n",
    "1  5   6   7   8   world\n",
    "2  9  10  11  12     foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_pickle(\"./examples/frame_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Podemos leer cualquier objeto “pickle” almacenado en un archivo usando\n",
    "directamente el módulo interno pickle, o usando `pandas.read_pickle`:\n",
    "\n",
    "*ADVERTENCIA.- El módulo `pickle` no es seguro. Solo utilícelo para\n",
    "de-serializar datos en los que confía.*\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle(\"./examples/frame_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[82]: \n",
    "   a   b   c   d message\n",
    "0  1   2   3   4   hello\n",
    "1  5   6   7   8   world\n",
    "2  9  10  11  12     foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "pandas tiene soporte interno para dos formatos más de datos binarios:\n",
    "HDF5 y MessagePack. Es conveniente explorar diferentes formatos de\n",
    "archivo para ver qué tan rápido son y qué tan bien funcionan para el\n",
    "análisis. Algunos otros formatos de almacenamiento para pandas o datos\n",
    "NumPy incluyen:\n",
    "\n",
    "-   *Bcolz*       Un formato binario compresible orientado a columnas,\n",
    "    basado en la biblioteca de compresión Blosc.\n",
    "\n",
    "-   *Feather*    Un formato de archivo orientado a columnas. Feather\n",
    "    utiliza el formato de memoria en columna de Apache Arrow.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formato HDF5\n",
    "\n",
    " \n",
    "\n",
    "HDF5 es un formato de archivo util para almacenar grandes cantidades de\n",
    "datos científicos. Está disponible como una biblioteca C y tiene\n",
    "interfaces disponibles en muchos otros lenguajes, incluidos Java, Julia,\n",
    "MATLAB y Python. “HDF” en HDF5 significa *“hierarchical data format”*.\n",
    "Cada archivo HDF5 puede almacenar múltiples conjuntos de datos y\n",
    "metadatos de soporte. En comparación con formatos más simples, HDF5\n",
    "admite la compresión sobre la marcha con una variedad de modos de\n",
    "compresión, lo que permite que los datos con patrones repetidos se\n",
    "almacenen de manera más eficiente. HDF5 puede ser una buena opción para\n",
    "trabajar con conjuntos de datos muy grandes que no caben en la memoria,\n",
    "ya que puede leer y escribir eficientemente pequeñas secciones de\n",
    "conjuntos mucho más grandes.\n",
    "\n",
    "Si bien es posible acceder directamente a los archivos HDF5 utilizando\n",
    "las bibliotecas PyTables o h5py, pandas proporciona una interfaz de alto\n",
    "nivel que simplifica el almacenamiento de objetos Series y DataFrame. La\n",
    "clase `HDFStore` funciona como un dict y maneja los detalles de bajo\n",
    "nivel:\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({'a': np.random.randn(100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore(\"./examples/misdatos.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['obj1'] = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['obj1_col'] = frame['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[87]: \n",
    "<class 'pandas.io.pytables.HDFStore'>\n",
    "File path: ... /examples/misdatos.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetos contenidos en el archivo HDF5 se pueden recuperar con la\n",
    "misma API tipo dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['obj1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[88]: \n",
    "           a\n",
    "0   1.095631\n",
    "1  -0.657863\n",
    "2  -1.247815\n",
    "3  0.697702\n",
    "4  -0.790224\n",
    "..       ...\n",
    "95 -0.294331\n",
    "96 -0.286762\n",
    "97 -0.055261\n",
    "98 -0.395597\n",
    "99 -0.187181\n",
    "\n",
    "[100 rows x 1 columns]\n",
    "```\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HDFStore` admite dos esquemas de almacenamiento, `'fixed'` y `'table'`.\n",
    "Este último generalmente es más lento, pero admite operaciones de\n",
    "consulta utilizando una sintaxis especial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.put('obj2', frame, format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " store.select('obj2', where=['index >= 10 and index <= 15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [91]: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "`put` es una versión explícita del método `store['obj2'] = frame` pero\n",
    "nos permite establecer otras opciones como el formato de almacenamiento.\n",
    "\n",
    "La función `pandas.read_hdf` ofrece un acceso directo a estas\n",
    "herramientas:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_hdf(\"./examples/misdatos.h5\", 'obj3', format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_hdf(\"./examples/misdatos.h5\", 'obj3', where=['index < 5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si está procesando datos almacenados en servidores remotos, como Amazon\n",
    "S3 o HDFS, puede ser más adecuado usar un formato binario diferente\n",
    "diseñado para almacenamiento distribuido como Apache Parquet. Python\n",
    "para Parquet y otros formatos de almacenamiento similares aún están en\n",
    "desarrollo.\n",
    "\n",
    "Dado que muchos problemas de análisis de datos son acotados en E/S (en\n",
    "lugar de acotados en CPU), el uso de una herramienta como HDF5 puede\n",
    "acelerar enormemente sus aplicaciones.\n",
    "\n",
    "HDF5 no es una base de datos. Es más adecuado para conjuntos de datos de\n",
    "escribe una vez y lee muchas veces. Si bien los datos se pueden agregar\n",
    "a un archivo en cualquier momento, si varios escritores lo hacen\n",
    "simultáneamente, el archivo puede corromperse.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivos de Microsoft Excel\n",
    "\n",
    " \n",
    "\n",
    "pandas también admite la lectura de datos tabulares almacenados en\n",
    "archivos Excel 2003 (y superiores) utilizando la clase `ExcelFile` o la\n",
    "función `pandas.read_excel`. Internamente, estas herramientas usan los\n",
    "paquetes complementarios `xlrd` y `openpyxl` para leer archivos XLS y\n",
    "XLSX, respectivamente. Es posible que deba instalarlos manualmente con\n",
    "pip o conda.\n",
    "\n",
    "Para usar `ExcelFile`, cree una instancia pasando una ruta a un archivo\n",
    "`xls` o `xlsx`:\n",
    "\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = pd.ExcelFile(\"./examples/ex1.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Los datos almacenados en una hoja se pueden leer en DataFrame con\n",
    "`parse`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel(xlsx, 'Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Si estamos leyendo varias hojas en un archivo, entonces es más rápido\n",
    "crear el `ExcelFile`, pero también podemos simplemente pasar el nombre\n",
    "del archivo a `pandas.read_excel`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_excel(\"./examples/ex1.xlsx\", 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para escribir datos de pandas en formato Excel, primero debemos crear un\n",
    "ExcelWriter`, luego escribir datos con el método`to\\_excel\\` de los\n",
    "objetos pandas:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"./examples/ex2-nuevo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_excel(writer, 'Sheet1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "También podemos pasar una ruta de archivo a `to_excel` y evitar\n",
    "`ExcelWriter`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_excel(\"./examples/ex2-nuevo.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interacción con APIs para web\n",
    "-----------------------------\n",
    "\n",
    " \n",
    "\n",
    "Muchos sitios web tienen API públicas que proporcionan datos a través de\n",
    "JSON o algún otro formato. Hay varias formas de acceder a estas API\n",
    "desde Python; un método fácil de usar es el `requests package`.\n",
    "\n",
    "Para encontrar las últimas 30 entradas de GitHub para pandas en GitHub,\n",
    "podemos hacer una solicitud `GET HTTP` utilizando la biblioteca\n",
    "`requests`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.github.com/repos/pandas-dev/pandas/issues'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.thecatapi.com/v1/images/search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "El método `json` del objeto Response retornará un diccionario que\n",
    "contiene objetos JSON convertidos a objetos nativos de Python:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = resp.json() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[108]: 'REF: share more methods in ExtensionIndex '\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Cada elemento en data es un diccionario que contiene todos los datos\n",
    "encontrados en una página de problemas de GitHub (excepto por los\n",
    "comentarios). Podemos pasar data directamente a DataFrame y extraer\n",
    "campos de interés:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = pd.DataFrame(data, columns=['number', 'title', 'state'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = pd.DataFrame(data)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rekp=requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rekp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[8]: \n",
    "    number                                              title  \\\n",
    "0    37980                                      DOC: Fix typo   \n",
    "1    37979  Should FilePathorBuffer use os.PathLike instea...   \n",
    "2    37977  BUG: CategoricalIndex.where nulling out non-ca...   \n",
    "3    37974         BUG: fix astype conversion string -> float   \n",
    "4    37973                      BLD: set inplace in setup.cfg   \n",
    "5    37972  TST: add nullable array frame constructor dtyp...   \n",
    "6    37971                        PERF: IntervalArray.argsort   \n",
    "7    37967  BUG: Limited available color name list when us...   \n",
    "8    37966                                   Read csv headers   \n",
    "9    37965  BUG: Make DTI/TDI/PI argsort match their under...   \n",
    "10   37964  BUG: Bug in setitem raising ValueError when se...   \n",
    "11   37963  BUG: Some string methods treat \".\" as regex, o...   \n",
    "12   37962                   „case-when“ function is missing?   \n",
    "13   37958          BUG: DataFrame.to_html ignores formatters   \n",
    "14   37957             STYLE: fail on pd.testing direct usage   \n",
    "15   37956  ENH: Add argument \"multiprocessing\" to DataFra...   \n",
    "16   37955  ENH: Add argument \"multiprocessing\" to pd.read...   \n",
    "17   37954  BUG: df.__setitem__ can be 10x slower than pd....   \n",
    "18   37950      ENH: 2D compat for DTA tz_localize, to_period   \n",
    "19   37949            ENH: IntervalIndex as groups in groupby   \n",
    "20   37947  Slow autocompletion in python/ipython console ...   \n",
    "21   37941  ENH: An argument for .query() that returns all...   \n",
    "22   37939  QST: how to run Pandas tests involving Numba o...   \n",
    "23   37937  BUG: Concat automatically sorts index when axi...   \n",
    "24   37935  BUG: json_normalize() upcasts column with miss...   \n",
    "25   37933             ENH: make closed part of IntervalDtype   \n",
    "26   37932     BUG: loc.setitem with expansion expanding rows   \n",
    "27   37931                       BUG: loc.setitem corner case   \n",
    "28   37930   INT: include NA values in Categorical.categories   \n",
    "29   37929         API: make CategoricalDtype.__eq__ stricter   \n",
    "\n",
    "                                               labels state  \n",
    "0                                                  []  open  \n",
    "1                                                  []  open  \n",
    "2                                                  []  open  \n",
    "3   [{'id': 1817503692, 'node_id': 'MDU6TGFiZWwxOD...  open  \n",
    "4   [{'id': 129350, 'node_id': 'MDU6TGFiZWwxMjkzNT...  open  \n",
    "5   [{'id': 1465286368, 'node_id': 'MDU6TGFiZWwxND...  open  \n",
    "6                                                  []  open  \n",
    "7   [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
    "8                                                  []  open  \n",
    "9                                                  []  open  \n",
    "10  [{'id': 2822098, 'node_id': 'MDU6TGFiZWwyODIyM...  open  \n",
    "11  [{'id': 1741841389, 'node_id': 'MDU6TGFiZWwxNz...  open  \n",
    "12  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n",
    "13                                                 []  open  \n",
    "14  [{'id': 106935113, 'node_id': 'MDU6TGFiZWwxMDY...  open  \n",
    "15  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n",
    "16  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n",
    "17  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
    "18  [{'id': 13098779, 'node_id': 'MDU6TGFiZWwxMzA5...  open  \n",
    "19  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n",
    "20                                                 []  open  \n",
    "21  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n",
    "22  [{'id': 1954720290, 'node_id': 'MDU6TGFiZWwxOT...  open  \n",
    "23  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
    "24  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
    "25  [{'id': 31404521, 'node_id': 'MDU6TGFiZWwzMTQw...  open  \n",
    "26  [{'id': 2822098, 'node_id': 'MDU6TGFiZWwyODIyM...  open  \n",
    "27  [{'id': 2822098, 'node_id': 'MDU6TGFiZWwyODIyM...  open  \n",
    "28  [{'id': 78527356, 'node_id': 'MDU6TGFiZWw3ODUy...  open  \n",
    "29  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "Interacción con bases de datos\n",
    "------------------------------\n",
    "\n",
    " \n",
    "\n",
    "En un entorno empresarial, la mayoría de los datos no están almacenados\n",
    "en archivos de texto o Excel. Las bases de datos relacionales basadas en\n",
    "SQL (como SQL Server, PostgreSQL y MySQL) se usan ampliamente, y muchas\n",
    "bases de datos alternativas se han vuelto bastante populares. La\n",
    "elección de la base de datos generalmente depende del rendimiento, la\n",
    "integridad de los datos y las necesidades de escalamiento de una\n",
    "aplicación.\n",
    "\n",
    "Cargar datos de SQL en un DataFrame es bastante sencillo, y pandas tiene\n",
    "algunas funciones para simplificar el proceso. Como ejemplo, crearémos\n",
    "una base de datos SQLite usando el controlador interno de Python\n",
    "`sqlite3`:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    ...: CREATE TABLE test(a VARCHAR(20), b VARCHAR(20), c REAL, d INTEGER);\n",
    "    ...: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('mydata.sqlite')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(query)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<sqlite3.Cursor at 0x7f8388906340>\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insertamos algunas filas de datos:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Atlanta', 'Georgia', 1.25, 6),\n",
    "    ...:         ('Tallahassee', 'Florida', 2.6, 3),\n",
    "    ...:         ('Sacramento', 'California', 1.7, 5)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.executemany(stmt, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Out[17]:<sqlite3.Cursor at 0x7f838897fe30>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    " \n",
    "\n",
    "La mayoría de los controladores Python de SQL (PyODBC, psycopg2,\n",
    "MySQLdb, pymssql, etc.) devuelven una lista de tuplas al seleccionar\n",
    "datos de una tabla:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = con.execute('select * from test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Podemos pasar la lista de tuplas al constructor DataFrame, pero también\n",
    "necesitamos los nombres de columna, contenidos en el atributo\n",
    "`description` del cursor:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[22]: \n",
    "(('a', None, None, None, None, None, None),\n",
    " ('b', None, None, None, None, None, None),\n",
    " ('c', None, None, None, None, None, None),\n",
    " ('d', None, None, None, None, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rows, columns=[x[0] for x in cursor.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[23]: \n",
    "             a           b     c  d\n",
    "0      Atlanta     Georgia  1.25  6\n",
    "1  Tallahassee     Florida  2.60  3\n",
    "2   Sacramento  California  1.70  5\n",
    "```\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas tiene una función `read_sql` que permite leer datos fácilmente\n",
    "desde una conexión SQLAlchemy. Aquí, nos conectaremos a la misma base de\n",
    "datos SQLite con SQLAlchemy y leeremos datos de la tabla creada\n",
    "anteriormente:\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sqla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqla.create_engine('sqlite:///mydata.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('select * from test', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[28]: \n",
    "             a           b     c  d\n",
    "0      Atlanta     Georgia  1.25  6\n",
    "1  Tallahassee     Florida  2.60  3\n",
    "2   Sacramento  California  1.70  5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Con frecuencia, el primer paso en el proceso de análisis de datos es\n",
    "obtener acceso a los datos. Hemos analizado una serie de herramientas\n",
    "útiles en este capítulo que deberán ayudar al respecto. En los próximos\n",
    "capítulos profundizaremos en el manejo de datos, la visualización de\n",
    "datos y el análisis de series de tiempo.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Bibliografía\n",
    "------------\n",
    "\n",
    " \n",
    "\n",
    "\\[1\\] *Python for Data Analysis, Data Wrangling with Pandas, NumPy, and\n",
    "IPython, Wes McKinney, 2nd. edition, 2018.*\n",
    "\n",
    "\\[2\\]\n",
    "*<a href=\"https://docs.python.org/3/\" class=\"uri\">https://docs.python.org/3/</a>*\n",
    "\n",
    "\\[3\\]\n",
    "*<a href=\"https://docs.python.org/3/tutorial/index.html\" class=\"uri\">https://docs.python.org/3/tutorial/index.html</a>*\n",
    "\n",
    "\\[4\\]\n",
    "*<a href=\"https://numpy.org/doc/stable/\" class=\"uri\">https://numpy.org/doc/stable/</a>*\n",
    "\n",
    "\\[5\\]\n",
    "*<a href=\"https://pandas.pydata.org/\" class=\"uri\">https://pandas.pydata.org/</a>*\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
